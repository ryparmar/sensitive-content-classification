{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fb8d59-1b4e-455f-9e88-39d514dd6c47",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "97fb8d59-1b4e-455f-9e88-39d514dd6c47",
     "kernelId": ""
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1f843-bf38-41c5-8646-df97c2c14654",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "43d1f843-bf38-41c5-8646-df97c2c14654",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "import transformers\n",
    "import cloudpickle\n",
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, List, Dict\n",
    "from pathlib import Path\n",
    "from sys import version_info\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EvalPrediction,\n",
    ")\n",
    "\n",
    "from utils import merge_title_perex_body\n",
    "from textra_tools import initialize_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb378b-360d-4888-a899-0d6b94f0abff",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0479b-71dc-4b02-9376-44bb768756f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data filepaths\n",
    "SENSITIVE_DATA_FILEPATH = \"data/processed-sensitive-data.csv\"\n",
    "SENSITIVE_DATA_AUGMENTED_FILEPATH = \"data/augmented-all.csv\"\n",
    "NON_SENSITIVE_DATA_FILEPATH = \"data/processed-nonsensitive-data.csv\"\n",
    "\n",
    "# Output data filepath\n",
    "OUTPUT_DIR = \"distilbert_5ep_weighted_CE_loss_w_augmented_data\"\n",
    "\n",
    "OUTPUT_MODEL_DIR = Path(os.path.join(OUTPUT_DIR, \"model\"))\n",
    "OUTPUT_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_MODEL_DIR = str(OUTPUT_MODEL_DIR)\n",
    "\n",
    "VAL_SET_RATIO = TEST_SET_RATIO = 0.10\n",
    "RANDOM_SEED = 11\n",
    "NONSENSITIVE_SAMPLE = 5000\n",
    "\n",
    "MLFLOW_URL = \"https://mlflow.lsnews.eu\"\n",
    "EXPERIMENT_NAME = \"en-sensitive-data\"\n",
    "RUN_NAME = \"distilbert_5ep_weighted_CE_loss_w_augmented_data\"\n",
    "\n",
    "STAGE_AUTH = \"textra-developers.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = STAGE_AUTH\n",
    "PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(\n",
    "    major=version_info.major, minor=version_info.minor, micro=version_info.micro\n",
    ")  # for mlflow model logging\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb611f09-55d1-4d9b-a084-dc67720c383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = initialize_experiment(experiment_name=EXPERIMENT_NAME, url=MLFLOW_URL, credentials=STAGE_AUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5789fa2-c116-4adc-9ede-93d438003436",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run(experiment_id=experiment_id, run_name=RUN_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f33ed8-ff6a-4772-a4b5-e98987c729a8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "42f33ed8-ff6a-4772-a4b5-e98987c729a8",
     "kernelId": ""
    }
   },
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07862b6a-8532-482b-aa21-272f2bfc4331",
   "metadata": {},
   "source": [
    "Run below commands to merge augmented splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc083799-3105-40f0-8ac0-f15fc965921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat data/augmented_1.csv > data/augmented-all.csv\n",
    "# !cat data/augmented_2.csv >> data/augmented-all.csv\n",
    "# !cat data/augmented_3.csv >> data/augmented-all.csv\n",
    "# !cat data/augmented_4.csv >> data/augmented-all.csv\n",
    "# !wc -l data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd2965-e174-45f1-9c80-fcfe72dcdeee",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "65dd2965-e174-45f1-9c80-fcfe72dcdeee",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sensitive = pd.read_csv(SENSITIVE_DATA_FILEPATH)  # index_col=0\n",
    "df_sensitive_augmented = pd.read_csv(SENSITIVE_DATA_AUGMENTED_FILEPATH)\n",
    "df_sensitive_augmented = df_sensitive_augmented[df_sensitive_augmented.id != \"id\"]  # remove rows created due to merging\n",
    "df_nonsensitive = pd.read_csv(NON_SENSITIVE_DATA_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2616018-7ecf-4a8d-b918-1ebff74f17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a331ab-21d1-4e57-9886-30c65427de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_augmented.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d140b2-0082-4448-af91-fb4b7238fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_augmented.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc6aab-0e84-40f3-9012-70067b542518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert id to string for easier manipulation\n",
    "df_sensitive_augmented[\"id\"] = df_sensitive_augmented[\"id\"].astype(str)\n",
    "df_sensitive[\"id\"] = df_sensitive[\"id\"].astype(str)\n",
    "df_nonsensitive[\"id\"] = df_nonsensitive[\"id\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8d356-9c5c-4084-857b-e3142da5b957",
   "metadata": {},
   "source": [
    "## Subsample nonsensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf9bdc-33ba-4f1e-9065-dd82e4133ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonsensitive = df_nonsensitive.sample(frac=1, random_state=RANDOM_SEED)[:NONSENSITIVE_SAMPLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4274296-25de-4aee-a3a4-95a7da6d6a5e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a4274296-25de-4aee-a3a4-95a7da6d6a5e",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sensitive[\"sensitive\"] = True\n",
    "df_sensitive_augmented[\"sensitive\"] = True\n",
    "df_nonsensitive[\"sensitive\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff0c40-6e55-496d-a08c-43b6776d9293",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "63ff0c40-6e55-496d-a08c-43b6776d9293",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "set(df_sensitive.id) & set(df_nonsensitive.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b04bc0-b8f6-44eb-a832-2c2866143ce2",
   "metadata": {},
   "source": [
    "### 1.1 Concatenate the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2444f-5c0b-402e-9468-4b82ba552bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive[\"text\"] = df_sensitive.apply(merge_title_perex_body, axis=1)\n",
    "df_nonsensitive[\"text\"] = df_nonsensitive.apply(merge_title_perex_body, axis=1)\n",
    "\n",
    "df_sensitive.drop([\"title\", \"perex\", \"body\"], axis=1, inplace=True)\n",
    "df_nonsensitive.drop([\"title\", \"perex\", \"body\"], axis=1, inplace=True)\n",
    "\n",
    "df_sensitive = df_sensitive.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "df_nonsensitive = df_nonsensitive.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c99dd-87ab-4348-b39e-52b6207f4c3c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "295c99dd-87ab-4348-b39e-52b6207f4c3c",
     "kernelId": ""
    }
   },
   "source": [
    "### 1.2 Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10815688-e225-48be-9d4b-2a84fd0ee867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(df, train_ratio=0.6, validation_ratio=0.2, seed=RANDOM_SEED):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_ratio * m)\n",
    "    validation_end = int(validation_ratio * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validation = df.iloc[perm[train_end:validation_end]]\n",
    "    test = df.iloc[perm[validation_end:]]\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8446f-1d03-4eda-aeda-109b023aef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive_train, df_sensitive_val, df_sensitive_test = train_validation_test_split(\n",
    "    df_sensitive, train_ratio=0.8, validation_ratio=VAL_SET_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fea574-a6d0-44fc-8a47-084ab33f9d85",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "52fea574-a6d0-44fc-8a47-084ab33f9d85",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_sensitive_train) + len(df_sensitive_val) + len(df_sensitive_test) == len(df_sensitive)\n",
    "print(\n",
    "    f\"Number of sensitive training data: {len(df_sensitive_train)}\\nNumber of sensitive validation data: {len(df_sensitive_val)}\\nNumber of sensitive test data: {len(df_sensitive_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981671e6-a95c-41f4-9589-28584ef1f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonsensitive_train, df_nonsensitive_val, df_nonsensitive_test = train_validation_test_split(\n",
    "    df_nonsensitive, train_ratio=0.8, validation_ratio=VAL_SET_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb4bb8-0eee-4ab3-a28c-337abd2522ef",
   "metadata": {
    "gradient": {
     "id": "e8eb4bb8-0eee-4ab3-a28c-337abd2522ef",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_nonsensitive_train) + len(df_nonsensitive_val) + len(df_nonsensitive_test) == len(df_nonsensitive)\n",
    "print(\n",
    "    f\"Number of nonsensitive training data: {len(df_nonsensitive_train)}\\nNumber of nonsensitive validation data: {len(df_nonsensitive_val)}\\nNumber of nonsensitive test data: {len(df_nonsensitive_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df0ebd-e634-455b-93ba-626af3380050",
   "metadata": {},
   "source": [
    "### 1.3 Merge with augmented data\n",
    "\n",
    "Need to be done after train/val/test split, so we can avoid to train-val-test data bleeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5d125-d109-4831-bcb5-698757d4a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_sensitive_augmented.iterrows():\n",
    "    if row.id[1:] in df_sensitive_train.id.values:\n",
    "        df_sensitive_train = df_sensitive_train.append(row, ignore_index=True)\n",
    "    elif row.id[1:] in df_sensitive_val.id.values:\n",
    "        df_sensitive_val = df_sensitive_val.append(row, ignore_index=True)\n",
    "    elif row.id[1:] in df_sensitive_test.id.values:\n",
    "        df_sensitive_test = df_sensitive_test.append(row, ignore_index=True)\n",
    "    else:\n",
    "        print(f\"ERROR: {row.id} could not be found anywhere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb96b5-c874-4f86-a593-5ca6aa0c516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_sensitive_augmented) + len(df_sensitive) == len(df_sensitive_train) + len(df_sensitive_val) + len(\n",
    "    df_sensitive_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0a5c8-ab69-45c7-8a6b-b8cf01beda0d",
   "metadata": {},
   "source": [
    "### 1.4 Merge sensitive and nonsensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f20fa-3459-4093-902a-7e5c286410fe",
   "metadata": {
    "gradient": {
     "id": "650f20fa-3459-4093-902a-7e5c286410fe",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_sensitive_train.merge(df_nonsensitive_train, how=\"outer\")\n",
    "df_val = df_sensitive_val.merge(df_nonsensitive_val, how=\"outer\")\n",
    "df_test = df_sensitive_test.merge(df_nonsensitive_test, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7daf12-09df-4727-a736-e5d47e92e48d",
   "metadata": {
    "gradient": {
     "id": "9c7daf12-09df-4727-a736-e5d47e92e48d",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of training data: {len(df_train)}\\nNumber of validation data: {len(df_val)}\\nNumber of test data: {len(df_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c800b-4cfe-484e-bdd4-66b78b8b326c",
   "metadata": {
    "gradient": {
     "id": "5b4c800b-4cfe-484e-bdd4-66b78b8b326c",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e18f4-edfd-47b6-af99-1bf316c40f70",
   "metadata": {},
   "source": [
    "## 2. Get Tokenizer and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f922f2-8a23-4808-9c1c-23fb2fe69693",
   "metadata": {},
   "source": [
    "Define label mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b2a9c-fb61-4fe9-adfd-4ead5a0e311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"nonsensitive\": 0,\n",
    "    \"sensitive\": 1,\n",
    "}\n",
    "id2label = {\n",
    "    0: \"nonsensitive\",\n",
    "    1: \"sensitive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac3d3c-3829-49b4-8bd7-2827ee781afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-cased\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name, label2id=label2id, id2label=id2label, num_labels=2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b58e5f-bb43-4d4f-971a-802f8915c270",
   "metadata": {},
   "source": [
    "## 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca4b12-ad5c-455b-bcac-94dcf1f46bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, is_test=False):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = self.data.text.values.tolist()\n",
    "        self.label = self.data.sensitive.values.tolist()\n",
    "        self.is_test = is_test  # if the label is not present\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        tokenized = tokenizer(self.text[item], truncation=True)\n",
    "        if not self.is_test:\n",
    "            return {\n",
    "                \"label\": int(self.label[item]),\n",
    "                \"input_ids\": tokenized[\"input_ids\"],\n",
    "                \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"input_ids\": tokenized[\"input_ids\"],\n",
    "                \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496161a-5c80-44cf-a916-f12d2b887e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetRetriever(df_train, tokenizer)\n",
    "val_dataset = DatasetRetriever(df_val, tokenizer)\n",
    "test_dataset = DatasetRetriever(df_test, tokenizer)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c13b13c-c225-4720-92f8-aeb18db4e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and log data\n",
    "data_path = Path(os.path.join(OUTPUT_DIR, \"data\"))\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(os.path.join(data_path, \"train.csv\"))\n",
    "df_val.to_csv(os.path.join(data_path, \"val.csv\"))\n",
    "df_test.to_csv(os.path.join(data_path, \"test.csv\"))\n",
    "\n",
    "mlflow.log_artifact(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ddaacb-3ce3-4b88-9ab5-c973bde28937",
   "metadata": {},
   "source": [
    "## 4. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090b300-70c6-47e8-934e-efee4d736477",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsensitive_weight = 1 - df_train.sensitive.value_counts()[False] / len(df_train)\n",
    "sensitive_weight = 1 - df_train.sensitive.value_counts()[True] / len(df_train)\n",
    "\n",
    "print(f\"Nonsensitive weight {nonsensitive_weight}\\nSensitive weight {sensitive_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0296ab-e5be-4936-8ac6-68fd5e79e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a\n",
    "# predictions and label_ids field) and has to return a dictionary string to float.\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd7d10-4a33-4479-bc5c-715971e4169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, weights=[nonsensitive_weight, sensitive_weight], return_outputs=False):\n",
    "        assert len(weights) == 2\n",
    "        labels = inputs.get(\"labels\").to(\"cpu\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\").to(\"cpu\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float).to(\"cpu\"))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac17bc5-989a-47c8-a3ac-332ca1dc542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    seed=RANDOM_SEED,\n",
    "    overwrite_output_dir=\"True\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c33c9-c890-4b50-a807-199174a7ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "metrics[\"train_samples\"] = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log training arguments to mlflow\n",
    "for arg in str(training_args).split(\"\\n\")[1:-1]:\n",
    "    arg, arg_val = arg.strip(\",\").strip(\"_\").split(\"=\")\n",
    "    mlflow.log_param(arg, arg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cac9a3-0265-4eac-b040-696a379ee37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(OUTPUT_MODEL_DIR)  # Saves the tokenizer too for easy upload\n",
    "\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "mlflow.log_artifact(\"results/all_results.json\")\n",
    "mlflow.log_artifact(\"results/trainer_state.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabac9f5-2f5c-4c70-8095-9e79cf5c2ef7",
   "metadata": {},
   "source": [
    "### Eval on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(df_report: pd.DataFrame, split: str):\n",
    "    \"\"\"Method that logs metrics to mlflow from classification report\"\"\"\n",
    "    class_mapping = {\"accuracy\": \"acc\"}\n",
    "    metric_mapping = {\"precision\": \"prec\", \"recall\": \"rec\", \"f1-score\": \"f1\"}\n",
    "    for class_name, class_values in df_report.iterrows():\n",
    "        log_class_name = (\n",
    "            f\"{split}_{class_mapping[class_name]}\".replace(\" \", \"_\")\n",
    "            if class_name in class_mapping\n",
    "            else f\"{split}_{class_name}\".replace(\" \", \"_\")\n",
    "        )\n",
    "        for metric_name, metric_val in zip(class_values.index, class_values.values):\n",
    "            log_metric_name = (\n",
    "                f\"{log_class_name}_{metric_mapping[metric_name]}\"\n",
    "                if metric_name in metric_mapping\n",
    "                else f\"{log_class_name}_{metric_name}\"\n",
    "            )\n",
    "            if log_metric_name.startswith(f\"{split}_acc\"):\n",
    "                if log_metric_name.endswith(\"prec\"):\n",
    "                    mlflow.log_metric(f\"{split}_acc\", metric_val)\n",
    "            else:\n",
    "                mlflow.log_metric(log_metric_name, metric_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdee76f-cd15-420f-8525-06e2d02665ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_path = Path(os.path.join(OUTPUT_DIR, \"reports\"))\n",
    "reports_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60964bb9-f354-4518-bb3d-f2e7de80dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(train_dataset, metric_key_prefix=\"predict\").predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "true = [i[\"label\"] for i in train_dataset]\n",
    "\n",
    "print(classification_report(true, predictions, target_names=[\"nonsensitive\", \"sensitive\"]))\n",
    "\n",
    "clf_report = classification_report(true, predictions, target_names=[\"nonsensitive\", \"sensitive\"], output_dict=True)\n",
    "df_report = pd.DataFrame(clf_report).transpose()\n",
    "df_report.to_csv(os.path.join(reports_path, \"clf_report_train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5824c8-83f4-465c-a2a7-750fae1808c5",
   "metadata": {},
   "source": [
    "### Eval on val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339a5fa-7b1a-49ad-90fe-e739d1272b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(val_dataset, metric_key_prefix=\"predict\").predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "true = [i[\"label\"] for i in val_dataset]\n",
    "\n",
    "print(classification_report(true, predictions, target_names=[\"nonsensitive\", \"sensitive\"]))\n",
    "\n",
    "clf_report = classification_report(true, predictions, target_names=[\"nonsensitive\", \"sensitive\"], output_dict=True)\n",
    "df_report = pd.DataFrame(clf_report).transpose()\n",
    "df_report.to_csv(os.path.join(reports_path, \"clf_report_val.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0161f3-eca2-4fd2-a2e6-5d6436826505",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13150aa7-9571-4dbc-b6d4-11c597da5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset, metric_key_prefix=\"predict\").predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "true = [i[\"label\"] for i in test_dataset]\n",
    "\n",
    "print(classification_report(true, predictions, target_names=[\"nonsensitive\", \"sensitive\"]))\n",
    "\n",
    "clf_report = classification_report(true, predictions, target_names=[\"nonsensitive\", \"sensitive\"], output_dict=True)\n",
    "df_report = pd.DataFrame(clf_report).transpose()\n",
    "df_report.to_csv(os.path.join(reports_path, \"clf_report_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cad53d-8f83-48a0-ab24-9acfd8dd8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_artifact(reports_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f71bff-2c6e-4c4b-908d-5e3c19e5b567",
   "metadata": {},
   "source": [
    "### Log to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b68bf-7693-4eb7-9370-ba158ceff7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_artifact(OUTPUT_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dbeca-8cb4-49de-90ed-3b79d02636a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model_tokenizer_path: str):\n",
    "        self.model_tokenizer_path = model_tokenizer_path\n",
    "\n",
    "    def load_context(self, context):\n",
    "        from transformers import (\n",
    "            AutoTokenizer,\n",
    "            AutoModelForSequenceClassification,\n",
    "        )\n",
    "        print(\"Tokenizer initialization...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(context.artifacts[\"model_tokenizer_path\"])\n",
    "        print(\"Model initialization...\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(context.artifacts[\"model_tokenizer_path\"], config=config)\n",
    "        # Optimize model by quantization -> weights represented using int8 instead of float32\n",
    "        self.model = torch.quantization.quantize_dynamic(self.model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "        print(\"Model is initialized!\")\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame):\n",
    "        text = (model_input.title + \" \" + model_input.lead + \" \" + model_input.body).tolist()\n",
    "        tokenized = self.tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\", padding=True)\n",
    "        prediction = self.model(**tokenized).logits\n",
    "        prediction = torch.softmax(prediction, axis=1)  # convert outputs to [0, 1] range, i.e. probability prediction\n",
    "        prediction = prediction.cpu().detach().numpy()\n",
    "        pred_index = list(np.argmax(prediction, axis=1))\n",
    "        output = [{'isSensitive': True if pred_index == 1 else False, 'score': prediction[i, p], 'id': sample_id} for i, (p, sample_id) in enumerate(zip(pred_index, model_input.id))]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3fce3d-0aea-49bc-b6a8-50d287a4ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = {\n",
    "    \"model_tokenizer_path\": f\"{OUTPUT_MODEL_DIR}\",\n",
    "}\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        \"python={}\".format(PYTHON_VERSION),\n",
    "        \"pip\",\n",
    "        {\n",
    "            \"pip\": [\n",
    "                \"mlflow=={}\".format(mlflow.__version__),\n",
    "                \"transformers[onnx]=={}\".format(transformers.__version__),\n",
    "                \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
    "                \"torch==1.11.0\",\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"transformers_env\",\n",
    "}\n",
    "\n",
    "input_schema = input_schema = Schema(\n",
    "    [\n",
    "        ColSpec(\"string\", \"id\"),\n",
    "        ColSpec(\"string\", \"title\"),\n",
    "        ColSpec(\"string\", \"lead\"),\n",
    "        ColSpec(\"string\", \"body\"),\n",
    "    ]\n",
    ")\n",
    "signature = ModelSignature(inputs=input_schema)\n",
    "\n",
    "# Log PyTorch model\n",
    "print(f\"Running {run.info.run_id} run\")\n",
    "print(f\"mlflow models serve -m runs:/{run.info.run_id}/{OUTPUT_MODEL_DIR} --no-conda\")\n",
    "# if --no-conda is deprecated\n",
    "# print(f\"mlflow models serve -m runs:/{run.info.run_id}/{OUTPUT_MODEL_DIR} --env-manager local\\n\\n\")\n",
    "mlflow.pyfunc.log_model(\n",
    "    artifact_path=OUTPUT_MODEL_DIR,\n",
    "    python_model=TransformerWrapper(model_tokenizer_path=OUTPUT_MODEL_DIR),\n",
    "    artifacts=artifacts,\n",
    "    conda_env=conda_env,\n",
    "    signature=signature,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fbfc0-c4e7-4b1f-834f-99afba3d1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6ba71ed456c7c7da9b4490b91c05d67ec06230d66828af52192873c8e577ebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
